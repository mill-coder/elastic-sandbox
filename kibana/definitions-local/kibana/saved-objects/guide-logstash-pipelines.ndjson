{"attributes": {"controlGroupInput": {"chainingSystem": "HIERARCHICAL", "controlStyle": "oneLine", "ignoreParentSettingsJSON": "{\"ignoreFilters\": false, \"ignoreQuery\": false, \"ignoreTimerange\": false, \"ignoreValidations\": false}", "panelsJSON": "{}", "showApplySelections": false}, "description": "Detailed guide for designing, deploying, and monitoring Logstash pipelines", "kibanaSavedObjectMeta": {"searchSourceJSON": "{\"filter\": [], \"query\": {\"query\": \"\", \"language\": \"kuery\"}}"}, "optionsJSON": "{\"useMargins\": true, \"syncColors\": false, \"syncCursor\": true, \"syncTooltips\": false, \"hidePanelTitles\": false}", "panelsJSON": "[{\"type\": \"visualization\", \"embeddableConfig\": {\"savedVis\": {\"title\": \"Overview\", \"description\": \"\", \"type\": \"markdown\", \"params\": {\"fontSize\": 12, \"openLinksInNewTab\": false, \"markdown\": \"## Logstash in this Sandbox\\n\\nThis sandbox runs Logstash with **centrally-managed pipelines** \\u2014 pipeline definitions are stored in Elasticsearch (the `.logstash` index) and Logstash polls for changes every 5 seconds.\\n\\n### Architecture\\n\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510     \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510     \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502  .conf files \\u2502\\u2500\\u2500\\u2500\\u2500\\u25b6\\u2502  deploy script    \\u2502\\u2500\\u2500\\u2500\\u2500\\u25b6\\u2502 Elasticsearch\\u2502\\n\\u2502  (local)     \\u2502     \\u2502  (Kibana API)     \\u2502     \\u2502 .logstash idx\\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518     \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518     \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u252c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n                                                       \\u2502 poll\\n                                                \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u25bc\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n                                                \\u2502   Logstash   \\u2502\\n                                                \\u2502  (container) \\u2502\\n                                                \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u252c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n                                                       \\u2502\\n                                        \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n                                        \\u2502              \\u2502              \\u2502\\n                                  \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u25bc\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u25bc\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u25bc\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n                                  \\u2502  Elastic   \\u2502 \\u2502  Health   \\u2502 \\u2502  Logs via \\u2502\\n                                  \\u2502  Agent     \\u2502 \\u2502  Checker  \\u2502 \\u2502  DLQ      \\u2502\\n                                  \\u2502(monitoring)\\u2502 \\u2502 (sidecar) \\u2502 \\u2502           \\u2502\\n                                  \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n**Satellite containers:**\\n- **Elastic Agent** \\u2014 collects Logstash JSON logs into `logs-logstash.log-*`\\n- **Pipeline Health Checker** \\u2014 polls Logstash API, emits health metrics into `logs-logstash.pipelines-*`\"}, \"uiState\": {}, \"data\": {\"aggs\": [], \"searchSource\": {\"query\": {\"query\": \"\", \"language\": \"kuery\"}, \"filter\": []}}}, \"enhancements\": {}}, \"panelIndex\": \"lg-overview\", \"gridData\": {\"i\": \"lg-overview\", \"x\": 0, \"y\": 0, \"w\": 48, \"h\": 16}}, {\"type\": \"visualization\", \"embeddableConfig\": {\"savedVis\": {\"title\": \"Step-by-Step Guide\", \"description\": \"\", \"type\": \"markdown\", \"params\": {\"fontSize\": 12, \"openLinksInNewTab\": false, \"markdown\": \"## Step-by-Step Guide\\n\\n### 1. Start the stack\\n\\n```bash\\npodman compose -f install/compose.yaml \\\\\\n  --env-file install/local/.env \\\\\\n  --profile kibana --profile logstash up -d\\n```\\n\\nThis starts: Elasticsearch, Kibana, Logstash, Elastic Agent, and the Pipeline Health Checker.\\n\\n### 2. Write a pipeline\\n\\nCreate a `.conf` file in `logstash/pipelines/`. Example structure:\\n\\n```ruby\\ninput {\\n  # Your input plugin (http_poller, jdbc, generator, etc.)\\n}\\n\\nfilter {\\n  # Optional transformations\\n}\\n\\noutput {\\n  elasticsearch {\\n    hosts => [\\\"${LOGSTASH_ES_HOSTS}\\\"]\\n    user => \\\"${LOGSTASH_ES_USER}\\\"\\n    password => \\\"${LOGSTASH_ES_PASSWORD}\\\"\\n    index => \\\"logs-myapp-default\\\"\\n  }\\n}\\n```\\n\\nThe filename (without `.conf`) becomes the **pipeline ID**.\\n\\n### 3. Deploy\\n\\n**Option A \\u2014 Script (recommended for batch deploys):**\\n```bash\\ninstall/deploy-logstash-pipelines.sh\\n```\\nThis uploads all `.conf` files from `logstash/pipelines/` to Kibana's Pipeline Management API.\\n\\n**Option B \\u2014 Kibana UI:**\\nGo to [Pipeline Management](/app/management/logstash/pipelines), click \\\"Create pipeline\\\", paste your config.\\n\\n### 4. Monitor\\n\\nOpen the [Logstash Monitoring dashboard](/app/dashboards#/view/f8a015a7-5bdf-489a-8db4-19944db6be5c). Key metrics:\\n- **Instance status** \\u2014 green/yellow/red overall health\\n- **Pipeline Stats table** \\u2014 events in/out, DLQ, reload failures per pipeline\\n- **Events Over Time** \\u2014 throughput trend chart\\n- **Errors Over Time** \\u2014 error spikes by pipeline\\n\\n### 5. Debug\\n\\n- Check the **Recent Errors** panel for stack traces\\n- Look at **Top Errors by Pipeline** to find recurring issues\\n- Use [Discover](/app/discover) with the `Logs - *` data view, filter to `data_stream.dataset: logstash.log`\\n- Check DLQ metrics for poisoned events\\n\\n### 6. Iterate\\n\\nEdit your `.conf` file and re-run the deploy script. Logstash picks up changes within ~5 seconds (centrally-managed polling interval).\"}, \"uiState\": {}, \"data\": {\"aggs\": [], \"searchSource\": {\"query\": {\"query\": \"\", \"language\": \"kuery\"}, \"filter\": []}}}, \"enhancements\": {}}, \"panelIndex\": \"lg-steps\", \"gridData\": {\"i\": \"lg-steps\", \"x\": 0, \"y\": 16, \"w\": 48, \"h\": 28}}, {\"type\": \"visualization\", \"embeddableConfig\": {\"savedVis\": {\"title\": \"Pipeline .conf Format\", \"description\": \"\", \"type\": \"markdown\", \"params\": {\"fontSize\": 12, \"openLinksInNewTab\": false, \"markdown\": \"## Pipeline `.conf` Format\\n\\n### Structure\\n\\nEvery Logstash pipeline has three sections:\\n\\n```ruby\\ninput {\\n  # One or more input plugins\\n}\\n\\nfilter {\\n  # Zero or more filter plugins (optional)\\n}\\n\\noutput {\\n  # One or more output plugins\\n}\\n```\\n\\n### Environment variables\\n\\nThese are available inside all pipeline `.conf` files:\\n\\n| Variable | Default | Description |\\n|----------|---------|-------------|\\n| `LOGSTASH_ES_HOSTS` | `http://elasticsearch:9200` | Elasticsearch cluster URL |\\n| `LOGSTASH_ES_USER` | `logstash` | Elasticsearch username |\\n| `LOGSTASH_ES_PASSWORD` | `password` | Elasticsearch password |\\n\\nUse them with `${VAR_NAME}` syntax in your pipeline config.\\n\\n### Tips\\n\\n- **Pipeline ID** = filename without `.conf` extension\\n- Use `generator` input for testing (produces synthetic events)\\n- Use `stdout { codec => rubydebug }` output for debugging\\n- Set `log.level=debug` in Logstash settings for verbose logging\"}, \"uiState\": {}, \"data\": {\"aggs\": [], \"searchSource\": {\"query\": {\"query\": \"\", \"language\": \"kuery\"}, \"filter\": []}}}, \"enhancements\": {}}, \"panelIndex\": \"lg-conf\", \"gridData\": {\"i\": \"lg-conf\", \"x\": 0, \"y\": 44, \"w\": 24, \"h\": 16}}, {\"type\": \"visualization\", \"embeddableConfig\": {\"savedVis\": {\"title\": \"Reference Pipelines\", \"description\": \"\", \"type\": \"markdown\", \"params\": {\"fontSize\": 12, \"openLinksInNewTab\": false, \"markdown\": \"## Reference Pipelines\\n\\nExample pipelines in `logstash/pipelines/reference/`:\\n\\n| Pipeline | File | Description |\\n|----------|------|-------------|\\n| DLQ Reader | `_dlq_reader.conf` | Reads dead-letter-queue events and re-indexes them for inspection |\\n| HTTP Poller | `http_poller.conf.example` | Polls an HTTP endpoint on a schedule and indexes the response |\\n| ES-to-ES Transform | `es_to_es_transform.conf.example` | Reads from one ES index, transforms, writes to another |\\n| ES Import | `es_import.conf.example` | Bulk import from an external Elasticsearch cluster |\\n| WWW Availability | `www_availability.conf` | Checks website availability and records response times |\\n\\n### Using a reference pipeline\\n\\n1. Copy the file to `logstash/pipelines/` (remove `.example` suffix if present)\\n2. Edit the configuration (inputs, filters, outputs) for your use case\\n3. Deploy with `install/deploy-logstash-pipelines.sh`\"}, \"uiState\": {}, \"data\": {\"aggs\": [], \"searchSource\": {\"query\": {\"query\": \"\", \"language\": \"kuery\"}, \"filter\": []}}}, \"enhancements\": {}}, \"panelIndex\": \"lg-reference\", \"gridData\": {\"i\": \"lg-reference\", \"x\": 24, \"y\": 44, \"w\": 24, \"h\": 16}}, {\"type\": \"visualization\", \"embeddableConfig\": {\"savedVis\": {\"title\": \"Monitoring Dashboard\", \"description\": \"\", \"type\": \"markdown\", \"params\": {\"fontSize\": 12, \"openLinksInNewTab\": false, \"markdown\": \"## Monitoring Dashboard\\n\\nThe [Logstash Monitoring dashboard](/app/dashboards#/view/f8a015a7-5bdf-489a-8db4-19944db6be5c) provides real-time visibility into pipeline health.\\n\\n### Data sources\\n\\n| Data stream | Producer | Content |\\n|-------------|----------|---------|\\n| `logs-logstash.pipelines-*` | Pipeline Health Checker | Instance health + per-pipeline stats (every ~10s) |\\n| `logs-logstash.log-*` | Elastic Agent | Logstash JSON log output |\\n\\n### Key panels\\n\\n| Panel | What it shows |\\n|-------|---------------|\\n| Pipeline Health | Overall status (green/yellow/red) + running pipeline count |\\n| DLQ Bytes / Dropped | Dead-letter-queue size and dropped event count |\\n| Pipeline Stats | Per-pipeline table: events in/out, duration, reloads, DLQ |\\n| Events In/Out Over Time | Throughput trend (line chart, split by pipeline) |\\n| Errors Over Time | Error count (bar chart, split by pipeline) |\\n| Top Errors by Pipeline | Aggregated error messages grouped by pipeline + plugin |\\n| Recent Errors | Latest error log entries with full messages |\\n| Logstash Logs | All log entries with color-coded log levels |\"}, \"uiState\": {}, \"data\": {\"aggs\": [], \"searchSource\": {\"query\": {\"query\": \"\", \"language\": \"kuery\"}, \"filter\": []}}}, \"enhancements\": {}}, \"panelIndex\": \"lg-monitoring\", \"gridData\": {\"i\": \"lg-monitoring\", \"x\": 0, \"y\": 60, \"w\": 24, \"h\": 14}}, {\"type\": \"visualization\", \"embeddableConfig\": {\"savedVis\": {\"title\": \"Troubleshooting\", \"description\": \"\", \"type\": \"markdown\", \"params\": {\"fontSize\": 12, \"openLinksInNewTab\": false, \"markdown\": \"## Troubleshooting\\n\\n### Pipeline not appearing\\n\\n- **Check deployment**: Run `install/deploy-logstash-pipelines.sh` \\u2014 look for success output\\n- **Check .logstash index**: `curl -s -u elastic:changeme http://localhost:9200/.logstash/_search?pretty`\\n- **Check Logstash logs**: Filter to `data_stream.dataset: logstash.log` in Discover\\n- **Polling delay**: Logstash polls every 5 seconds \\u2014 wait a moment after deploying\\n\\n### Pipeline shows \\\"missing\\\" status\\n\\nThe health checker reports `missing` when a pipeline is defined in `.logstash` but not running in the Logstash process. Common causes:\\n- Syntax error in the `.conf` file \\u2014 check Logstash logs for parsing errors\\n- Missing plugin \\u2014 the pipeline uses a plugin not installed in the Logstash image\\n- Resource exhaustion \\u2014 JVM heap too small for the number of pipelines\\n\\n### DLQ growing\\n\\nEvents land in the Dead Letter Queue when they can't be indexed. Common causes:\\n- **Mapping conflict** \\u2014 field type mismatch between document and index mapping\\n- **Index read-only** \\u2014 disk watermark exceeded, index set to read-only\\n\\nInspect DLQ events using the `_dlq_reader` reference pipeline.\\n\\n### High error rate\\n\\n- Check **Top Errors by Pipeline** for the most frequent error messages\\n- Look for `connection refused` errors (Elasticsearch down or unreachable)\\n- Look for `codec` errors (malformed input data)\\n- Set `log.level=debug` temporarily for more detail\\n\\n### Health checker not running\\n\\n```bash\\npodman logs pipeline-health-checker\\n```\\n\\nThe health checker needs both Elasticsearch and the Logstash API to be reachable.\"}, \"uiState\": {}, \"data\": {\"aggs\": [], \"searchSource\": {\"query\": {\"query\": \"\", \"language\": \"kuery\"}, \"filter\": []}}}, \"enhancements\": {}}, \"panelIndex\": \"lg-troubleshoot\", \"gridData\": {\"i\": \"lg-troubleshoot\", \"x\": 24, \"y\": 60, \"w\": 24, \"h\": 14}}]", "timeRestore": false, "title": "Guide: Logstash Pipeline Development", "version": 3}, "coreMigrationVersion": "8.8.0", "created_at": "2026-02-13T00:22:10.000Z", "id": "dev-guide-00000000-0000-0000-0000-000000000002", "managed": false, "references": [], "type": "dashboard", "typeMigrationVersion": "10.3.0", "updated_at": "2026-02-13T00:22:10.000Z", "version": "WzEsMV0="}
{"excludedObjects": [], "excludedObjectsCount": 0, "exportedCount": 1, "missingRefCount": 0, "missingReferences": []}
